{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import utils\n",
    "\n",
    "model_dir = \"experiments/\"\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "params = utils.Params(json_path)\n",
    "params.device = torch.device(params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.data_loader import DataLoader\n",
    "\n",
    "data_dir = \"data/full_version/\"\n",
    "data_loader = DataLoader(data_dir, params)\n",
    "params.vocab_size = len(data_loader.BABYNAME.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.charRNN as net\n",
    "model = net.Net(params).to(params.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = os.path.join(model_dir, \"best.pth.tar\")\n",
    "checkpoint = utils.load_checkpoint(weight_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, prime=\"A\", category=\"boy\"):\n",
    "    \n",
    "    category_tensor = data_loader.SEX.process(['boy']).data.sub_(1).float()\n",
    "    \n",
    "    prime = prime.lower()\n",
    "    prime_tensor = data_loader.BABYNAME.process([prime])[:, :-1]\n",
    "    bsz, prime_tensor_length = prime_tensor.size()\n",
    "    \n",
    "    net.eval()\n",
    "    hidden = net.init_hidden(1)\n",
    "    \n",
    "    for step in range(prime_tensor_length):\n",
    "        outputs, hidden = net(category_tensor, prime_tensor[:, step], hidden)\n",
    "        probabilities = F.softmax(outputs, 1)\n",
    "    \n",
    "    return probabilities.squeeze()\n",
    "        \n",
    "probabilities = sample(model, prime=\"A\", category=\"boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_top_k(probabilities, k):\n",
    "    prob, idx = torch.topk(probabilities, k)\n",
    "    chars = [data_loader.BABYNAME.vocab.itos[char] for char in idx.cpu().numpy()]\n",
    "    return prob.detach().cpu().numpy(), chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(net, prime=\"A\", category=\"boy\", beam_width=3):\n",
    "    print(\"Sampling a {} name beginning with {}..\".format(category, prime))\n",
    "    \n",
    "    initial_probabilities = sample(net, prime=prime, category=category)\n",
    "    \n",
    "    _prob_dict = {}\n",
    "    prob, chars = calcualte_top_k(initial_probabilities, beam_width)\n",
    "    for p, c in zip(prob, chars):\n",
    "        _prob_dict[prime + c] = p\n",
    "        \n",
    "    _prob_dict_2 = {}\n",
    "    for prime, prob in _prob_dict.items():\n",
    "        probabilities = sample(net, prime=prime, category=category)\n",
    "        prob, chars = calcualte_top_k(probabilities, probabilities.size(0))\n",
    "        for p, c in zip(prob, chars):\n",
    "            _prob_dict_2[prime + c] = p\n",
    "    \n",
    "    print(_prob_dict_2)\n",
    "    \n",
    "beam_search(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, prime, category, hidden=None):\n",
    "    \n",
    "    category_tensor = data_loader.SEX.process(['boy']).data.sub_(1).float()\n",
    "    \n",
    "    prime = prime.lower()\n",
    "    prime_tensor = data_loader.BABYNAME.process([prime])[:, :-1]\n",
    "    bsz, prime_tensor_length = prime_tensor.size()\n",
    "    \n",
    "    net.eval()\n",
    "    if not hidden:\n",
    "        hidden = net.init_hidden(1)\n",
    "    \n",
    "    for step in range(prime_tensor_length):\n",
    "        with torch.no_grad():\n",
    "            outputs, hidden = net(category_tensor, prime_tensor[:, step], hidden)\n",
    "        probabilities = F.softmax(outputs, 1)\n",
    "    \n",
    "    return torch.log(probabilities.squeeze()), hidden\n",
    "        \n",
    "probabilities, prime_hidden = sample(model, prime=\"A\", category=\"boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_beam_basket(basket, beam_width):\n",
    "    _tmp_basket = basket.copy()\n",
    "    to_remove = sorted(_tmp_basket.items(), key=lambda x: x[1], reverse=True)[beam_width:]\n",
    "    for item in to_remove:\n",
    "        _tmp_basket.pop(item[0])\n",
    "        \n",
    "    return _tmp_basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_creativity(name_list, dataset):\n",
    "    for a_name in name_list:\n",
    "        if dataset.babyname.str.contains(a_name).sum() > 0:\n",
    "            verdict = \"is already in the dataset\"\n",
    "        else:\n",
    "            verdict = \"is a new name!\"\n",
    "        print(\"name: {} \".format(a_name) + verdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(net, prime=\"A\", category=\"boy\", beam_width=3):\n",
    "    print(\"Sampling a {} name beginning with {}..\".format(category, prime))\n",
    "        \n",
    "    beam_basket = OrderedDict()\n",
    "    beam_basket[prime] = 0.0\n",
    "    hidden_dict = defaultdict()\n",
    "    \n",
    "    \n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        \n",
    "        # 바스켓을 청소한다.\n",
    "        beam_basket = clean_beam_basket(beam_basket, beam_width)\n",
    "        \n",
    "        # 만약 바스켓에 모든 아이템이 <eos>가 있으면 루프를 멈춘다.\n",
    "        eos_cnt = 0\n",
    "        for k in beam_basket.keys():\n",
    "            if \"<eos>\" in k:\n",
    "                eos_cnt += 1\n",
    "        if eos_cnt == beam_width:\n",
    "            print(\"all items have <eos>\")\n",
    "            break\n",
    "            \n",
    "        # 모든 key를 돌면서\n",
    "        ## <eos>가 없는 경우 inference를 한다.\n",
    "        new_entries = {}\n",
    "        to_remove = []\n",
    "        for k in beam_basket.keys():\n",
    "            if \"<eos>\" not in k:\n",
    "                hidden = hidden_dict.get(k)\n",
    "                probabilities, hidden = sample(net, prime=k, category=category, hidden=hidden)\n",
    "                for ix, prob in enumerate(probabilities):\n",
    "                    new_k = k + data_loader.BABYNAME.vocab.itos[ix]\n",
    "                    new_entries[new_k] = beam_basket[k] + prob.item()\n",
    "                to_remove.append(k)\n",
    "        # 그리고 기존 key를 beam_basket에서 지운다.\n",
    "        for k in to_remove:\n",
    "            beam_basket.pop(k)\n",
    "        \n",
    "        for k, v in new_entries.items():\n",
    "            beam_basket[k] = v\n",
    "            \n",
    "    final_list = []\n",
    "    for k, v in beam_basket.items():\n",
    "        refined_k = k.replace(\"<eos>\", \"\").capitalize()\n",
    "        final_list.append(refined_k)\n",
    "        final_prob = np.exp(v)\n",
    "                \n",
    "    return final_list\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "final_list = beam_search(model, prime='A', category='boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(net, prime, category, beam_width, dataset):\n",
    "    final_list = beam_search(net, prime=prime, category=category, beam_width=beam_width)\n",
    "    \n",
    "    evaluate_creativity(final_list, dataset)\n",
    "    \n",
    "generate_names(model, prime=\"A\", category=\"girl\", beam_width=3, dataset=total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(net, prime, category, beam_width, dataset):\n",
    "    final_list = beam_search(net, prime=prime, category=category, beam_width=beam_width)\n",
    "    \n",
    "    evaluate_creativity(final_list, dataset)\n",
    "    \n",
    "generate_names(model, prime=\"A\", category=\"boy\", beam_width=3, dataset=total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_train = pd.read_csv(os.path.join(data_dir, \"train/train_dataset.csv\"))\n",
    "_val = pd.read_csv(os.path.join(data_dir, \"val/val_dataset.csv\"))\n",
    "total_df = pd.concat([_train, _val], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in final_list:\n",
    "    total_df[lambda x: x.babyname == name]\n",
    "    print(\"name: {} is \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.babyname.str.contains(\"Andrick\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[lambda x: x.babyname == \"Andrian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.get('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_basket = OrderedDict()\n",
    "beam_basket['A'] = 1.0\n",
    "beam_basket['B'] = 0.8\n",
    "beam_basket['C'] = 0.7\n",
    "beam_basket['D'] = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(beam_basket.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.BABYNAME.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
